{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Working on Time Series with Pandas\n"
      ],
      "metadata": {
        "id": "31Jttp1wh4FB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forecasting: Principles and Practice (3rd ed) [link](https://otexts.com/fpp3/)\n",
        "* Pandas documentation for time series(https://pandas.pydata.org/docs/user_guide/timeseries.html)"
      ],
      "metadata": {
        "id": "vj_kpgnag4E_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ch3BngGfzSw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.dates as mdates\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Generate three timestamps starting from \"2023-01-01\" with frequency of \"1 hr\"\n",
        "\n",
        "ts_index = pd.date_range('2023-01-01', periods = 3, freq = 'H')\n",
        "ts_index"
      ],
      "metadata": {
        "id": "dZF4sbk2i8Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the commonly used `freq` tags\n",
        "\n",
        "| Date Offset | Frequency String | Description        |\n",
        "|-------------|------------------|--------------------|\n",
        "| MonthEnd    | 'M'              | calendar month end |\n",
        "| Day         | 'D'              | one absolute day   |\n",
        "| Hour        | 'H'              | one hour           |\n",
        "| Minute      | 'T' or 'min'     | one minute         |\n",
        "| Second      | 'S'              | one second         |\n",
        "\n",
        "*Check this for other supported \"freq\" tags:\n",
        "https://pandas.pydata.org/docs/user_guide/timeseries.html#dateoffset-objects*\n",
        "\n"
      ],
      "metadata": {
        "id": "vJ3ElC6tjUdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manipulating and converting date times with timezone information**"
      ],
      "metadata": {
        "id": "nkBtTWB5pXaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Generate timestamps specific to timezones\n",
        "\n",
        "# Time zone UTC\n",
        "print(ts_index.tz_localize('UTC'))\n",
        "\n",
        "# Time zone Asia/kokata\n",
        "print(ts_index.tz_localize(\"Asia/kolkata\"))"
      ],
      "metadata": {
        "id": "TXbPq3-tjc08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "____\n",
        "**Task - 1**\n",
        "____\n",
        "\n",
        "Your manager has given you a climate timeseries dataset with 1000 rows and asked you to analyse it but the dataset **does not have a timestamp column**. You are informed that each row of this dataset represents outputs from different sensors.\n",
        "\n",
        "Your manager added that the observations were made starting from \"*12th jan 2020*\" and is **daily data**, meaning one obeservation recorded per day starting from `2020-01-12`.\n",
        "\n",
        "* Create a datetime index in pandas starting from `12th jan 2020` with `1000` observatiions.\n",
        "\n",
        "* Add timestamps as index to the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "H0vi2qtjpfuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read climate data set\n",
        "climate_data = pd.read_csv('https://tinyurl.com/mpbudws')\n",
        "print(climate_data.head(5))"
      ],
      "metadata": {
        "id": "5PVRVsFgIscp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate timestamp values\n",
        "start_date = '2020-01-12'\n",
        "data_length = climate_data.shape[0]\n",
        "timestamps = pd.date_range(start = start_date, periods = data_length, freq = 'D')\n",
        "\n",
        "# Add timestamp column to the climate_data\n",
        "climate_data['timestamps'] = timestamps\n",
        "climate_data = climate_data.set_index('timestamps')\n",
        "print(climate_data.head(5))"
      ],
      "metadata": {
        "id": "6ZclGaTgrb8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "____"
      ],
      "metadata": {
        "id": "V13MuSqB4o2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resampling a time series**"
      ],
      "metadata": {
        "id": "41XDa8ePpT6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Genrate hourly data with random values for 10 periods\n",
        "idx = pd.date_range('2010-01-01', periods = 10, freq = '1H')\n",
        "df = pd.DataFrame({'Values': np.random.rand(10)}, index = idx)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gdZ_qZS_2DuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform resampling, the daraframe index has to be in pandas DateTime format and we need to specify the aggregation fuction like `mean()`, `min()`, `max()`, etc. Refer to official documentation of pandas resample for more information. [pandas.DataFrame.resample](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html)"
      ],
      "metadata": {
        "id": "UZwmiqYokOWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Resample (in this case, downsample) the data to z frequency of \"2 hours\"\n",
        "df.resample('2H').mean()"
      ],
      "metadata": {
        "id": "YVQBTu4n20eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "____\n",
        "**Task - 2**\n",
        "____\n",
        "\n",
        "From your initial analysis of the climate data, you came to know that there is only a slight variation in the data on a daily basis. It is redundant to have too many values with no extra information and might cause computational overhead. So, you decide to convert the daily data to weekly data. In other words, you want to resample the climate time series from `1 day` to  `1 week`. The resampled values must be the maximum observation over the respective weeks.\n"
      ],
      "metadata": {
        "id": "YjjB58JD4uGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Resample the climate time series from 1 day to 1 week\n",
        "## with values as maximum over the week\n",
        "climate_data_resampled = climate_data.resample('W').max()\n",
        "climate_data_resampled.head()"
      ],
      "metadata": {
        "id": "SVfs_VI63zUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the climate time series data"
      ],
      "metadata": {
        "id": "pmGuYnMHS91s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot climate timeseries data\n",
        "colors = cm.rainbow(np.linspace(0, 1, 6))\n",
        "fig, ax = plt.subplots(2, 3, figsize = (14, 6), tight_layout = True)\n",
        "df_plot = climate_data_resampled\n",
        "for i in range(2):\n",
        "  for j in range(3):\n",
        "    col = df_plot.columns[i+2*j]\n",
        "    ax[i,j].plot(df_plot.index, df_plot[col], color = colors[i+2*j])\n",
        "    ax[i, j].set_xlabel('Timestamp', fontsize = 8)\n",
        "    ax[i, j].set_ylabel('Values', fontsize = 8)\n",
        "    ax[i, j].set_title(col, fontsize = 12)\n",
        "    ax[i, j].xaxis.set_major_locator(mdates.MonthLocator(bymonth = range(1, 12, 3)))\n",
        "    ax[i, j].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
        "    ax[i, j].tick_params(axis = 'x', rotation = 90);"
      ],
      "metadata": {
        "id": "0cJTgKlsS9Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performing date and time arithmetic with absolute or relative time increments**"
      ],
      "metadata": {
        "id": "R9TRKu8zMRCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date1 = pd.Timestamp('2018-01-05')\n",
        "\n",
        "# add 2 days, 5 hours and 10 minutes to 1st date\n",
        "date2 = date1 + pd.Timedelta('2D 5H 10min')\n",
        "\n",
        "date2"
      ],
      "metadata": {
        "id": "yq55PhmOMUup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "____\n",
        "\n",
        "**Task - 3**\n",
        "____\n",
        "\n",
        "Assume that the data you have was collected in India. You want to store this data in an internal database, and your database engineer tells you that their team can only work with `timestamps without time zone` (24  hour clock UTC). Achieve this by subtracting 5 hours and 30 minutes from all the values in the timestamp index.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iWVy_SAFNVyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "climate_data.head()"
      ],
      "metadata": {
        "id": "jbh1BK2EQaDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "climate_data.index = climate_data.index - pd.Timedelta('5H 30min')\n",
        "climate_data.head()"
      ],
      "metadata": {
        "id": "xsoSbZCYNIWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "____"
      ],
      "metadata": {
        "id": "RV-ZNeW8G7cA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Time Series Data Wrangling and Visualization**\n",
        "\n"
      ],
      "metadata": {
        "id": "lTZ7CAxWbw4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vizualising a subset of data using groupby and pivot. The data set consists of timestamps column `Date` (frequency is 1 day), `store` (store id), `product` (product id)  and `number_sold` (number of a product sold by a store)."
      ],
      "metadata": {
        "id": "NqIHw1MabYsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Data source: https://www.kaggle.com/datasets/samuelcortinhas/time-series-practice-dataset\n",
        "sales_data = pd.read_csv('https://tinyurl.com/mr2rv4yh')\n",
        "sales_data.head()"
      ],
      "metadata": {
        "id": "i93kxQvXLsoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "____\n",
        "\n",
        "**Task - 3**\n",
        "____\n",
        "\n",
        "\n",
        "Convert 'date' column type to pandas.datetime and set date as index of the dataframe"
      ],
      "metadata": {
        "id": "QIvtOWMtNOME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Date' column type to pandas.datetime\n",
        "sales_data['Date'] = pd.to_datetime(sales_data['Date'])\n",
        "\n",
        "# Set Date as index of the dataframe\n",
        "sales_data.set_index('Date', inplace = True)\n",
        "\n",
        "sales_data.head()"
      ],
      "metadata": {
        "id": "5UjIiau3MRVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Resample and forward fill null values\n",
        "grouping_cols = ['store', 'product']\n",
        "\n",
        "def resample_fn(data):\n",
        "  \"\"\"Resamples the time series to frequency\n",
        "  equal to 1 Week, using average of values\n",
        "  over the week and forward fill the nan values\n",
        "  if present.\n",
        "  \"\"\"\n",
        "  return data.resample('W').mean().fillna(method = 'ffill')\n",
        "\n",
        "## Resample the data belonging to each product of each store seperately\n",
        "## and group the data by 'store' and 'product' by applying the fuction above\n",
        "sales_data_processed = sales_data.groupby(grouping_cols, as_index = False).apply(resample_fn)\n",
        "sales_data_processed.head()"
      ],
      "metadata": {
        "id": "62i1tAY1MyJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Remove MultiIndex, only Date is required as Index\n",
        "sales_data_processed = sales_data_processed.reset_index(level = 0, drop = True)\n",
        "sales_data_processed.head()"
      ],
      "metadata": {
        "id": "QHAhBZx_aNUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot the sales of all the products from store id 0**"
      ],
      "metadata": {
        "id": "UAFlK6MjU3-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Filter the data for store id equal to 0\n",
        "store_id_0 = sales_data_processed[sales_data_processed['store'] == 0]"
      ],
      "metadata": {
        "id": "4JN6HXZ4U_uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Modify the data such that index represents date and\n",
        "## columns represent the product id\n",
        "\n",
        "store_0_pivot = store_id_0.pivot(columns = 'product', values = 'number_sold')\n",
        "store_0_pivot.head()"
      ],
      "metadata": {
        "id": "mlG-2WHQWAjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_0_pivot.plot(figsize = (10, 8))"
      ],
      "metadata": {
        "id": "9lEDobOwXhq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze how the sales of `product 1` of `store 0` have changed over the years"
      ],
      "metadata": {
        "id": "-PXRjsm_da6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter product id equal to 1 from store_0\n",
        "product_1_s0 = store_id_0[store_id_0['product'] == 1]"
      ],
      "metadata": {
        "id": "_B6DS2zQdaKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_1_s0.head()"
      ],
      "metadata": {
        "id": "ZSxYc0o8lH6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a column called year\n",
        "product_1_s0['Year'] = product_1_s0.index.year\n",
        "\n",
        "# Create a column called month\n",
        "product_1_s0['Month'] = product_1_s0.index.month\n",
        "\n",
        "# create a DataFrame whose index represents months and columns respresent years\n",
        "result_df = pd.pivot_table(product_1_s0,\n",
        "                           index = 'Month',\n",
        "                           columns = 'Year',\n",
        "                           values = 'number_sold',\n",
        "                           aggfunc = np.mean\n",
        "                           )\n",
        "result_df.head()"
      ],
      "metadata": {
        "id": "KZpP_ZMVih0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.plot(figsize=(10,8))"
      ],
      "metadata": {
        "id": "vvIiDhgTjTBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Moving average**"
      ],
      "metadata": {
        "id": "x557ct-dQG_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load stock price data\n",
        "df_stock = pd.read_csv(\"https://tinyurl.com/3fh8j4x8\")\n",
        "df_stock.head()"
      ],
      "metadata": {
        "id": "9Zk24hUzH6dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert date to pandas Date Time type, set Date as index\n",
        "## and resample the data to 1 day\n",
        "df_stock['Date'] = pd.to_datetime(df_stock['Date'])\n",
        "df_stock.set_index(['Date'], inplace = True)\n",
        "sampling_rate = df_stock.index[1] - df_stock.index[0]\n",
        "df_stock.resample(sampling_rate).mean().interpolate(method = 'linear')"
      ],
      "metadata": {
        "id": "JUvby-fUQWtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extract closing price of the stock and plot it\n",
        "stock_price = df_stock[['Close']]\n",
        "print(stock_price.head())\n",
        "stock_price.plot();"
      ],
      "metadata": {
        "id": "HC0QYllVRbhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Smoothen plot using moving average\n"
      ],
      "metadata": {
        "id": "9YcV98BnR3Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lag**"
      ],
      "metadata": {
        "id": "uL9m_xJ2SOPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute 4 lags for the closing stock price and add these as\n",
        "## additional columns to the Dataframe\n",
        "lag_1 = stock_price.shift(-1)\n",
        "lag_2 =\n",
        "lag_3 =\n",
        "lag4 =\n",
        "\n",
        "stock_price.loc[:, ['lag_1', 'lag_2', 'lag_3', 'lag_4']] = [lag_1, lag_2, lag_3, lag_4]\n",
        "stock_price.head(4)"
      ],
      "metadata": {
        "id": "VkbZRSPVSPfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot lagged timeseries data for the last 10 timestamps\n"
      ],
      "metadata": {
        "id": "KVtW_QuTTSMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autocorrelation**"
      ],
      "metadata": {
        "id": "ikF0zRvYTpPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Calculate autocorrelation between timeseries and its\n",
        "## lagged versions\n"
      ],
      "metadata": {
        "id": "QRYzrpy1TrjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Calculate correlation of closing price with all\n",
        "## lags\n",
        "for i in [\"lag_1\",\"lag_2\",\"lag_3\",\"lag_4\"]:"
      ],
      "metadata": {
        "id": "ammTSQ2AUDXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot 3 different timeseries: constant, linear, and\n",
        "## white noise\n",
        "plt.plot(np.arange(1000),np.repeat(5,1000), label=\"straight line\")\n",
        "plt.show()\n",
        "plt.plot(np.arange(1000),np.arange(1000))\n",
        "plt.show()\n",
        "plt.plot(np.random.randn(1000))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aD0A6LxBUkQ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}